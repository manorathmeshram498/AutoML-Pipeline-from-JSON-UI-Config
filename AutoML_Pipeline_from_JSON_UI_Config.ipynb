{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install striprtf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vc4lCqzDWO6F",
        "outputId": "2d216e1d-8728-4467-b1a2-33c138fb3219"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting striprtf\n",
            "  Downloading striprtf-0.0.29-py3-none-any.whl.metadata (2.3 kB)\n",
            "Downloading striprtf-0.0.29-py3-none-any.whl (7.9 kB)\n",
            "Installing collected packages: striprtf\n",
            "Successfully installed striprtf-0.0.29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7dbSBoKDUXRH"
      },
      "outputs": [],
      "source": [
        "from striprtf.striprtf import rtf_to_text\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import warnings\n",
        "import re\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"algoparams_from_ui.json.rtf\", \"r\") as file:\n",
        "    rtf_content = file.read()\n",
        "\n",
        "# Step 2: Convert to plain text (remove RTF formatting)\n",
        "plain_text = rtf_to_text(rtf_content)\n",
        "\n",
        "# Step 3: Parse the clean JSON\n",
        "json_data = json.loads(plain_text)\n",
        "\n",
        "design_data = json_data[\"design_state_data\"]\n",
        "target_config = design_data[\"target\"]\n",
        "prediction_type = target_config[\"prediction_type\"]\n",
        "target_column = target_config[\"target\"]\n",
        "feature_config = design_data[\"feature_handling\"]\n",
        "reduction_config = design_data[\"feature_reduction\"]\n",
        "algorithm_config = design_data[\"algorithms\"]\n",
        "hyperparam_config = design_data[\"hyperparameters\"]\n",
        "\n",
        "df = pd.read_csv(\"iris.csv\")"
      ],
      "metadata": {
        "id": "Tscav92KUndw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Step 2: Feature Handling (Imputation + Encoding) ==========\n",
        "selected_features = [f for f, conf in feature_config.items() if conf[\"is_selected\"]]\n",
        "numerical_features = []\n",
        "categorical_features = []\n",
        "imputers = {}\n",
        "\n",
        "for fname, conf in feature_config.items():\n",
        "    if not conf[\"is_selected\"]:\n",
        "        continue\n",
        "    ftype = conf[\"feature_variable_type\"]\n",
        "    details = conf[\"feature_details\"]\n",
        "\n",
        "    if ftype == \"numerical\":\n",
        "        numerical_features.append(fname)\n",
        "        strategy = 'mean' if details[\"impute_with\"] == \"Average of values\" else 'constant'\n",
        "        fill_value = details.get(\"impute_value\", 0)\n",
        "        imputers[fname] = SimpleImputer(strategy=strategy, fill_value=fill_value)\n",
        "    elif ftype == \"text\":\n",
        "        categorical_features.append(fname)\n",
        "\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean'))  # updated per-column later\n",
        "])\n",
        "cat_transformer = Pipeline(steps=[\n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', num_transformer, numerical_features),\n",
        "    ('cat', cat_transformer, categorical_features)\n",
        "])"
      ],
      "metadata": {
        "id": "QLBP1QjNUxSZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Step 3: Feature Reduction ==========\n",
        "reduction_method = reduction_config[\"feature_reduction_method\"]\n",
        "if reduction_method == \"No Reduction\":\n",
        "    reducer = \"passthrough\"\n",
        "elif reduction_method == \"PCA\":\n",
        "    reducer = PCA(n_components=int(reduction_config[\"num_of_features_to_keep\"]))\n",
        "elif reduction_method == \"Tree-based\":\n",
        "    reducer = SelectKBest(score_func=f_regression, k=int(reduction_config[\"num_of_features_to_keep\"]))\n",
        "else:\n",
        "    reducer = \"passthrough\""
      ],
      "metadata": {
        "id": "Ibc_oUWCWyop"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Step 4: Model Selection ==========\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "models = []\n",
        "param_grids = {}\n",
        "\n",
        "for model_key, model_conf in algorithm_config.items():\n",
        "    if not model_conf[\"is_selected\"]:\n",
        "        continue\n",
        "\n",
        "    if prediction_type == \"Regression\":\n",
        "\n",
        "        if model_key == \"RandomForestRegressor\":\n",
        "            model = RandomForestRegressor(random_state=42)\n",
        "            param_grid = {\n",
        "                'model__n_estimators': list(range(model_conf[\"min_trees\"], model_conf[\"max_trees\"] + 1, 5)),\n",
        "                'model__max_depth': list(range(model_conf[\"min_depth\"], model_conf[\"max_depth\"] + 1, 5)),\n",
        "                'model__min_samples_leaf': list(range(model_conf[\"min_samples_per_leaf_min_value\"],\n",
        "                                                      model_conf[\"min_samples_per_leaf_max_value\"] + 1, 5))\n",
        "            }\n",
        "\n",
        "        elif model_key == \"LinearRegression\":\n",
        "            model = LinearRegression()\n",
        "            param_grid = {\n",
        "                'model__fit_intercept': [True, False]\n",
        "            }\n",
        "\n",
        "        elif model_key == \"RidgeRegression\":\n",
        "            model = Ridge()\n",
        "            param_grid = {\n",
        "                'model__alpha': [round(x, 2) for x in\n",
        "                                 np.linspace(model_conf[\"min_regparam\"], model_conf[\"max_regparam\"], 3)],\n",
        "                'model__max_iter': list(range(model_conf[\"min_iter\"], model_conf[\"max_iter\"] + 1, 10))\n",
        "            }\n",
        "\n",
        "        elif model_key == \"LassoRegression\":\n",
        "            model = Lasso()\n",
        "            param_grid = {\n",
        "                'model__alpha': [round(x, 2) for x in\n",
        "                                 np.linspace(model_conf[\"min_regparam\"], model_conf[\"max_regparam\"], 3)],\n",
        "                'model__max_iter': list(range(model_conf[\"min_iter\"], model_conf[\"max_iter\"] + 1, 10))\n",
        "            }\n",
        "\n",
        "        elif model_key == \"ElasticNetRegression\":\n",
        "            model = ElasticNet()\n",
        "            param_grid = {\n",
        "                'model__alpha': [round(x, 2) for x in\n",
        "                                 np.linspace(model_conf[\"min_regparam\"], model_conf[\"max_regparam\"], 2)],\n",
        "                'model__l1_ratio': [round(x, 2) for x in\n",
        "                                    np.linspace(model_conf[\"min_elasticnet\"], model_conf[\"max_elasticnet\"], 2)],\n",
        "                'model__max_iter': list(range(model_conf[\"min_iter\"], model_conf[\"max_iter\"] + 1, 10))\n",
        "            }\n",
        "\n",
        "        elif model_key == \"GBTRegressor\":\n",
        "            model = GradientBoostingRegressor()\n",
        "            param_grid = {\n",
        "                'model__n_estimators': list(range(model_conf[\"min_iter\"], model_conf[\"max_iter\"] + 1, 10)),\n",
        "                'model__max_depth': list(range(model_conf[\"min_depth\"], model_conf[\"max_depth\"] + 1, 1)),\n",
        "                'model__learning_rate': [round(x, 2) for x in\n",
        "                                         np.linspace(model_conf[\"min_stepsize\"], model_conf[\"max_stepsize\"], 2)],\n",
        "                'model__subsample': list(range(model_conf[\"min_subsample\"], model_conf[\"max_subsample\"] + 1))\n",
        "            }\n",
        "\n",
        "        elif model_key == \"DecisionTreeRegressor\":\n",
        "            model = DecisionTreeRegressor()\n",
        "            param_grid = {\n",
        "                'model__max_depth': list(range(model_conf[\"min_depth\"], model_conf[\"max_depth\"] + 1)),\n",
        "                'model__min_samples_leaf': model_conf[\"min_samples_per_leaf\"]\n",
        "            }\n",
        "\n",
        "        else:\n",
        "            print(f\"⚠️ Unsupported or unhandled regression model: {model_key}\")\n",
        "            continue\n",
        "\n",
        "        models.append((model_key, model, param_grid))\n"
      ],
      "metadata": {
        "id": "r_8Oxu4FW35f"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[selected_features]\n",
        "y = df[target_column]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "RDs-SvQXXAJR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Step 6: Model Training and Evaluation ==========\n",
        "for name, model, param_grid in models:\n",
        "    pipe = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('reduction', reducer),\n",
        "        ('model', model)\n",
        "    ])\n",
        "\n",
        "    search = GridSearchCV(pipe, param_grid, cv=3, n_jobs=-1, verbose=1)\n",
        "    search.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = search.predict(X_test)\n",
        "    print(f\"\\n===== Model: {name} =====\")\n",
        "    print(\"Best Parameters:\", search.best_params_)\n",
        "    print(\"R2 Score:\", r2_score(y_test, y_pred))\n",
        "    print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
        "    print(\"MAE:\", mean_absolute_error(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEH-dqxjXkhc",
        "outputId": "849454e0-1e39-43cb-86c2-21f9ecc59048"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
            "\n",
            "===== Model: RandomForestRegressor =====\n",
            "Best Parameters: {'model__max_depth': 20, 'model__min_samples_leaf': 10, 'model__n_estimators': 20}\n",
            "R2 Score: 0.9632025216126167\n",
            "MSE: 0.023390521567375724\n",
            "MAE: 0.1243853175576651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QdcyzNXBXq7B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}